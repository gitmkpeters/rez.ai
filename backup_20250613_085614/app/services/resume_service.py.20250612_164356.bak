import logging
from werkzeug.utils import secure_filename
import re
import json

class ResumeService:
    def __init__(self, scraper, document_service, openai_service=None, pdf_service=None):
        """Initialize ResumeService with required dependencies"""
        self.scraper = scraper
        self.document_service = document_service
        self.openai_service = openai_service
        self.pdf_service = pdf_service
        self.logger = logging.getLogger(__name__)
        
        # Log initialization
        self.logger.info(f"ResumeService initialized with scraper={scraper is not None}, "
                        f"document_service={document_service is not None}, "
                        f"openai_service={openai_service is not None}, "
                        f"pdf_service={pdf_service is not None}")

    def process_job_url(self, url):
        """Process a job URL with intelligent fallbacks and URL fixing"""
        try:
            self.logger.info(f"Processing job URL: {url}")
            
            # Fix common URL issues
            fixed_url = self._fix_common_url_issues(url)
            if fixed_url != url:
                self.logger.info(f"Fixed URL from {url} to {fixed_url}")
            
            # Extract job description
            job_description = self.scraper.extract_job_description(fixed_url)
            
            return {
                "success": True,
                "job_description": job_description,
                "message": f"Successfully extracted {len(job_description)} characters from job posting",
                "url_used": fixed_url,
                "extraction_length": len(job_description)
            }
            
        except Exception as e:
            self.logger.warning(f"Failed to extract job description from {url}: {str(e)}")
            
            # Provide helpful error messages based on the site and error
            error_message = self._get_helpful_error_message(url, str(e))
            
            return {
                "success": False,
                "job_description": "",
                "message": error_message,
                "error": str(e),
                "url_used": url
            }

    def _fix_common_url_issues(self, url):
        """Fix common URL format issues"""
        # Fix LinkedIn collections URLs
        if "linkedin.com/jobs/collections" in url and "currentJobId=" in url:
            job_id_match = re.search(r'currentJobId=(\d+)', url)
            if job_id_match:
                job_id = job_id_match.group(1)
                fixed_url = f"https://www.linkedin.com/jobs/view/{job_id}"
                self.logger.info(f"Fixed LinkedIn collections URL to direct job URL")
                return fixed_url
        
        # Add more URL fixes as needed
        return url

    def _get_helpful_error_message(self, url, error):
        """Provide helpful error messages based on the site and error"""
        if "linkedin.com" in url:
            if "403" in error or "forbidden" in error.lower():
                return "LinkedIn is blocking automated access. Please copy and paste the job description manually."
            elif "page not found" in error.lower() or "404" in error:
                return "LinkedIn job posting not found. Please check the URL and try again, or copy the job description manually."
            else:
                return "LinkedIn job extraction failed. Please copy and paste the job description manually."
        
        elif "indeed.com" in url:
            if "403" in error or "forbidden" in error.lower():
                return "Indeed is blocking automated access. Please copy and paste the job description manually."
            else:
                return "Indeed job extraction failed. Please copy and paste the job description manually."
        
        elif "glassdoor.com" in url:
            return "Glassdoor job extraction failed. Please copy and paste the job description manually."
        
        else:
            return f"Could not extract job description from this site. Please copy and paste the job description manually."

    def process_resume(self, resume_file, job_description=None, job_url=None):
        """Process resume with job description or URL"""
        try:
            # Extract text from resume
            resume_filename = secure_filename(resume_file.filename)
            resume_text = self.document_service.extract_text_from_file(resume_file)
            
            # Get job description from URL if provided
            url_result = None
            if job_url and not job_description:
                url_result = self.process_job_url(job_url)
                
                if url_result["success"]:
                    job_description = url_result["job_description"]
                    self.logger.info(f"Successfully extracted job description from URL: {len(job_description)} characters")
                else:
                    # Return the error so the UI can handle it gracefully
                    return {
                        "success": False,
                        "message": url_result["message"],
                        "suggestion": "Please copy and paste the job description in the text area below.",
                        "url_error": True,
                        "url_result": url_result
                    }
            
            # Validate we have a job description
            if not job_description or len(job_description.strip()) < 50:
                return {
                    "success": False,
                    "message": "Please provide a job description (at least 50 characters) or a valid job URL"
                }
            
            # Process the resume and job description
            analysis_result = self._analyze_resume_vs_job(resume_text, job_description)
            
            # If OpenAI service is available, get enhanced analysis
            ai_analysis = None
            if self.openai_service:
                try:
                    ai_analysis = self.openai_service.analyze_resume_fit(resume_text, job_description)
                except Exception as e:
                    self.logger.warning(f"AI analysis failed, falling back to basic analysis: {str(e)}")
            
            return {
                "success": True,
                "resume_filename": resume_filename,
                "resume_text": resume_text,
                "job_description": job_description,
                "analysis": analysis_result,
                "ai_analysis": ai_analysis,
                "url_result": url_result,
                "message": "Resume processed successfully!"
            }
            
        except Exception as e:
            self.logger.error(f"Error processing resume: {str(e)}")
            return {
                "success": False,
                "message": f"Error processing resume: {str(e)}"
            }

    def _analyze_resume_vs_job(self, resume_text, job_description):
        """Analyze resume against job description with enhanced keyword extraction"""
        resume_words = len(resume_text.split())
        job_words = len(job_description.split())
        
        # Enhanced keyword extraction
        job_keywords = self._extract_keywords_enhanced(job_description)
        resume_keywords = self._extract_keywords_enhanced(resume_text)
        
        # Calculate matching keywords and their frequency
        matching_keywords = {}
        for keyword in job_keywords:
            if keyword in resume_keywords:
                matching_keywords[keyword] = min(job_keywords[keyword], resume_keywords[keyword])
        
        # Calculate match percentage based on keyword presence and frequency
        total_job_keyword_count = sum(job_keywords.values())
        total_matching_count = sum(matching_keywords.values())
        
        match_percentage = (total_matching_count / total_job_keyword_count * 100) if total_job_keyword_count else 0
        
        # Get top keywords by frequency
        top_job_keywords = sorted(job_keywords.items(), key=lambda x: x[1], reverse=True)[:15]
        top_resume_keywords = sorted(resume_keywords.items(), key=lambda x: x[1], reverse=True)[:15]
        top_matching = sorted(matching_keywords.items(), key=lambda x: x[1], reverse=True)[:15]
        
        return {
            "resume_word_count": resume_words,
            "job_word_count": job_words,
            "job_keywords": [k for k, v in top_job_keywords],
            "job_keyword_freq": dict(top_job_keywords),
            "resume_keywords": [k for k, v in top_resume_keywords],
            "resume_keyword_freq": dict(top_resume_keywords),
            "matching_keywords": [k for k, v in top_matching],
            "matching_keyword_freq": dict(top_matching),
            "match_percentage": match_percentage,
            "total_job_keywords": len(job_keywords),
            "total_resume_keywords": len(resume_keywords),
            "total_matching_keywords": len(matching_keywords)
        }

    def _extract_keywords_enhanced(self, text):
        """Extract keywords from text with enhanced NLP techniques"""
        # Convert to lowercase and split
        words = text.lower().split()
        
        # Remove common stop words
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 
                     'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 
                     'will', 'would', 'could', 'should', 'this', 'that', 'these', 'those', 'they', 'them',
                     'their', 'there', 'here', 'where', 'when', 'why', 'how', 'all', 'any', 'both', 'each',
                     'few', 'more', 'most', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',
                     'than', 'too', 'very', 'can', 'just', 'should', 'now'}
        
        # Extract single words
        word_freq = {}
        for word in words:
            # Clean word (remove punctuation)
            clean_word = re.sub(r'[^\w]', '', word)
            if len(clean_word) > 2 and clean_word not in stop_words:
                word_freq[clean_word] = word_freq.get(clean_word, 0) + 1
        
        # Extract multi-word phrases (2-3 words)
        text_lower = text.lower()
        
        # Common technical skills and job-related phrases
        common_phrases = [
            'machine learning', 'data science', 'artificial intelligence', 'deep learning',
            'project management', 'team leadership', 'customer service', 'problem solving',
            'data analysis', 'software development', 'web development', 'front end', 'back end',
            'full stack', 'quality assurance', 'user experience', 'user interface', 'devops',
            'cloud computing', 'database management', 'network security', 'system administration',
            'product management', 'agile methodology', 'scrum master', 'business intelligence',
            'digital marketing', 'content strategy', 'search engine optimization', 'social media',
            'financial analysis', 'risk management', 'strategic planning', 'sales experience',
            'customer relationship', 'human resources', 'talent acquisition', 'employee relations',
            'budget management', 'resource allocation', 'performance optimization', 'process improvement',
            'regulatory compliance', 'quality control', 'technical support', 'client relations',
            'market research', 'competitive analysis', 'business development', 'account management',
            'public relations', 'crisis management', 'brand development', 'creative direction',
            'content creation', 'video production', 'graphic design', 'ux design', 'ui design',
            'mobile development', 'ios development', 'android development', 'cross platform',
            'api integration', 'third party', 'data migration', 'legacy systems', 'ci cd',
            'continuous integration', 'continuous deployment', 'test automation', 'unit testing',
            'functional testing', 'performance testing', 'security testing', 'penetration testing',
            'vulnerability assessment', 'risk assessment', 'disaster recovery', 'business continuity',
            'change management', 'stakeholder management', 'vendor management', 'contract negotiation',
            'supply chain', 'inventory management', 'logistics coordination', 'warehouse management',
            'financial reporting', 'budget forecasting', 'cost reduction', 'revenue growth',
            'profit optimization', 'market expansion', 'customer acquisition', 'customer retention',
            'lead generation', 'sales funnel', 'conversion optimization', 'a b testing',
            'data visualization', 'statistical analysis', 'predictive modeling', 'natural language processing',
            'computer vision', 'reinforcement learning', 'neural networks', 'big data',
            'data warehousing', 'etl processes', 'data governance', 'data privacy',
            'information security', 'cyber security', 'cloud migration', 'hybrid cloud',
            'multi cloud', 'serverless architecture', 'microservices', 'container orchestration',
            'infrastructure as code', 'configuration management', 'resource provisioning', 'capacity planning',
            'performance monitoring', 'log analysis', 'incident response', 'problem resolution',
            'technical documentation', 'knowledge base', 'training development', 'curriculum design',
            'instructional design', 'learning management', 'talent development', 'succession planning',
            'compensation benefits', 'employee engagement', 'workplace culture', 'diversity inclusion',
            'executive leadership', 'cross functional', 'matrix management', 'remote team',
            'distributed workforce', 'global operations', 'international expansion', 'localization',
            'market entry', 'competitive positioning', 'value proposition', 'product differentiation',
            'customer segmentation', 'target audience', 'user persona', 'customer journey',
            'experience design', 'service design', 'design thinking', 'innovation management',
            'research development', 'product roadmap', 'feature prioritization', 'sprint planning',
            'release management', 'version control', 'code review', 'pair programming',
            'technical architecture', 'solution design', 'enterprise architecture', 'systems integration',
            'api design', 'database design', 'schema modeling', 'data normalization',
            'query optimization', 'index tuning', 'performance tuning', 'scalability planning',
            'high availability', 'fault tolerance', 'load balancing', 'traffic management',
            'content delivery', 'edge computing', 'iot devices', 'embedded systems',
            'firmware development', 'hardware integration', 'protocol implementation', 'network topology',
            'vpn configuration', 'firewall management', 'intrusion detection', 'threat mitigation',
            'compliance audit', 'security assessment', 'vulnerability management', 'patch management',
            'asset management', 'license compliance', 'software procurement', 'hardware procurement',
            'capital expenditure', 'operational expenditure', 'cost benefit', 'roi analysis',
            'financial modeling', 'investment strategy', 'portfolio management', 'wealth management',
            'estate planning', 'tax strategy', 'retirement planning', 'benefits administration',
            'payroll processing', 'time tracking', 'expense management', 'accounts payable',
            'accounts receivable', 'general ledger', 'financial statements', 'balance sheet',
            'income statement', 'cash flow', 'fundraising', 'investor relations',
            'board reporting', 'corporate governance', 'legal compliance', 'contract management',
            'intellectual property', 'patent filing', 'trademark registration', 'copyright protection'
        ]
        
        # Check for common phrases
        for phrase in common_phrases:
            count = text_lower.count(phrase)
            if count > 0:
                word_freq[phrase] = count
        
        # Extract programming languages, frameworks, and tools
        tech_keywords = [
            'python', 'java', 'javascript', 'typescript', 'c#', 'c++', 'ruby', 'php', 'swift', 'kotlin',
            'go', 'rust', 'scala', 'perl', 'r', 'matlab', 'sql', 'nosql', 'html', 'css', 'sass', 'less',
            'react', 'angular', 'vue', 'svelte', 'jquery', 'node.js', 'express', 'django', 'flask',
            'spring', 'hibernate', 'rails', 'laravel', 'symfony', 'asp.net', '.net core', 'xamarin',
            'flutter', 'react native', 'ionic', 'cordova', 'tensorflow', 'pytorch', 'keras', 'scikit-learn',
            'pandas', 'numpy', 'scipy', 'matplotlib', 'seaborn', 'tableau', 'power bi', 'qlik',
            'aws', 'azure', 'gcp', 'google cloud', 'firebase', 'heroku', 'digitalocean', 'netlify',
            'vercel', 'docker', 'kubernetes', 'jenkins', 'travis', 'circleci', 'github actions',
            'gitlab ci', 'terraform', 'ansible', 'puppet', 'chef', 'prometheus', 'grafana', 'elk stack',
            'elasticsearch', 'logstash', 'kibana', 'splunk', 'datadog', 'new relic', 'mongodb',
            'postgresql', 'mysql', 'oracle', 'sql server', 'sqlite', 'redis', 'cassandra', 'couchdb',
            'dynamodb', 'cosmosdb', 'kafka', 'rabbitmq', 'activemq', 'zeromq', 'nginx', 'apache',
            'iis', 'tomcat', 'jboss', 'websphere', 'weblogic', 'git', 'svn', 'mercurial',
            'jira', 'confluence', 'trello', 'asana', 'basecamp', 'slack', 'teams', 'zoom',
            'photoshop', 'illustrator', 'indesign', 'figma', 'sketch', 'adobe xd', 'invision',
            'zeplin', 'autocad', 'solidworks', 'revit', 'blender', 'unity', 'unreal engine',
            'office 365', 'g suite', 'excel', 'word', 'powerpoint', 'outlook', 'sharepoint',
            'salesforce', 'dynamics', 'hubspot', 'marketo', 'mailchimp', 'constant contact',
            'sap', 'oracle ebs', 'workday', 'netsuite', 'quickbooks', 'xero', 'stripe',
            'paypal', 'square', 'shopify', 'magento', 'woocommerce', 'wordpress', 'drupal',
            'joomla', 'squarespace', 'wix', 'webflow', 'bootstrap', 'material ui', 'tailwind',
            'foundation', 'bulma', 'semantic ui', 'ant design', 'chakra ui', 'styled components',
            'emotion', 'webpack', 'babel', 'gulp', 'grunt', 'parcel', 'rollup', 'vite', 'esbuild',
            'jest', 'mocha', 'chai', 'jasmine', 'karma', 'cypress', 'selenium', 'appium',
            'postman', 'swagger', 'openapi', 'graphql', 'rest', 'soap', 'grpc', 'websocket',
            'oauth', 'jwt', 'saml', 'ldap', 'active directory', 'kerberos', 'ssl', 'tls',
            'vpn', 'ssh', 'ftp', 'sftp', 'http', 'https', 'tcp', 'udp', 'ip', 'dns', 'dhcp'
        ]
        
        for keyword in tech_keywords:
            pattern = r'\b' + re.escape(keyword) + r'\b'
            matches = re.findall(pattern, text_lower)
            if matches:
                word_freq[keyword] = len(matches)
        
        return word_freq

    def generate_tailored_resume(self, user_info, job_description=None, job_url=None):
        """Generate a new resume from scratch using AI with tailored summary"""
        try:
            self.logger.info("Starting enhanced resume generation with tailored summary")
            
            # Get job description from URL if provided
            url_result = None
            if job_url and not job_description:
                url_result = self.process_job_url(job_url)
                if url_result["success"]:
                    job_description = url_result["job_description"]
                else:
                    return {
                        "success": False,
                        "message": url_result["message"]
                    }
            
            if not job_description:
                return {
                    "success": False,
                    "message": "Please provide a job description or valid job URL"
                }
            
            if not self.openai_service:
                return {
                    "success": False,
                    "message": "OpenAI service not available. Please check your API key."
                }
            
            # Extract user name for file naming
            user_name = self._extract_user_name(user_info)
            
            # Extract work experience and skills from user_info for tailored summary
            work_experience = self._extract_work_experience(user_info)
            user_skills = self._extract_skills(user_info)
            
            # Generate tailored summary first
            self.logger.info("Generating tailored professional summary")
            tailored_summary = self.openai_service.generate_tailored_summary(
                work_experience=work_experience,
                job_description=job_description,
                user_skills=user_skills
            )
            
            # Generate resume using AI with the tailored summary
            self.logger.info("Generating complete resume with tailored summary")
            generated_resume = self.openai_service.generate_resume(
                user_info, 
                job_description, 
                tailored_summary=tailored_summary
            )
            
            # Generate PDF of the resume
            pdf_result = None
            if self.pdf_service:
                pdf_result = self.pdf_service.generate_resume_pdf(generated_resume, user_name)
            
            # Automatically generate cover letter
            cover_letter_result = self.generate_cover_letter(
                user_info=user_info,
                job_description=job_description,
                company_name=self._extract_company_name(job_description)
            )
            
            # Analyze the generated resume against the job description
            analysis_result = self._analyze_resume_vs_job(generated_resume, job_description)
            
            return {
                "success": True,
                "generated_resume": generated_resume,
                "tailored_summary": tailored_summary,
                "job_description": job_description,
                "message": "Resume with tailored summary generated successfully!",
                "pdf_result": pdf_result,
                "cover_letter_result": cover_letter_result,
                "user_name": user_name,
                "analysis": analysis_result
            }
            
        except Exception as e:
            self.logger.error(f"Error generating resume: {str(e)}")
            return {
                "success": False,
                "message": f"Error generating resume: {str(e)}"
            }

    def generate_cover_letter(self, user_info, job_description=None, job_url=None, company_name=None):
        """Generate a cover letter using AI"""
        try:
            # Get job description from URL if provided
            if job_url and not job_description:
                url_result = self.process_job_url(job_url)
                if url_result["success"]:
                    job_description = url_result["job_description"]
                else:
                    return {
                        "success": False,
                        "message": url_result["message"]
                    }
            
            if not job_description:
                return {
                    "success": False,
                    "message": "Please provide a job description or valid job URL"
                }
            
            if not self.openai_service:
                return {
                    "success": False,
                    "message": "OpenAI service not available. Please check your API key."
                }
            
            # Extract user name for file naming
            user_name = self._extract_user_name(user_info)
            
            # Generate cover letter using AI
            generated_cover_letter = self.openai_service.generate_cover_letter(
                user_info, job_description, company_name
            )
            
            # Generate PDF of the cover letter
            pdf_result = None
            if self.pdf_service:
                pdf_result = self.pdf_service.generate_cover_letter_pdf(generated_cover_letter, user_name)
            
            return {
                "success": True,
                "generated_cover_letter": generated_cover_letter,
                "job_description": job_description,
                "message": "Cover letter generated successfully!",
                "pdf_result": pdf_result,
                "user_name": user_name
            }
            
        except Exception as e:
            self.logger.error(f"Error generating cover letter: {str(e)}")
            return {
                "success": False,
                "message": f"Error generating cover letter: {str(e)}"
            }

    def analyze_generated_resume(self, resume_content, job_description):
        """Analyze the quality of a generated resume against the job description"""
        try:
            if not self.openai_service:
                return {
                    "success": False,
                    "message": "OpenAI service not available. Please check your API key."
                }
            
            # Use OpenAI to analyze the resume
            analysis = self.openai_service.analyze_resume_fit(resume_content, job_description)
            
            # Also do enhanced keyword analysis
            basic_analysis = self._analyze_resume_vs_job(resume_content, job_description)
            
            return {
                "success": True,
                "ai_analysis": analysis,
                "keyword_analysis": basic_analysis,
                "message": "Resume analysis completed successfully!"
            }
            
        except Exception as e:
            self.logger.error(f"Error analyzing generated resume: {str(e)}")
            return {
                "success": False,
                "message": f"Error analyzing resume: {str(e)}"
            }

    def _extract_user_name(self, user_info):
        """Extract user name from user info for file naming"""
        # Look for name in the user_info string
        lines = user_info.split('\n')
        for line in lines:
            if 'Name:' in line:
                return line.replace('Name:', '').strip()
        
        # Fallback to first line or default
        first_line = lines[0].strip() if lines else "User"
        return first_line.replace('Name:', '').strip() or "User"

    def _extract_work_experience(self, user_info):
        """Extract work experience section from user info"""
        lines = user_info.split('\n')
        experience_section = []
        in_experience = False
        
        for line in lines:
            if 'Work Experience:' in line or 'Employment:' in line or 'Experience:' in line:
                in_experience = True
                continue
            elif in_experience and any(section in line for section in ['Education:', 'Skills:', 'Name:', 'Email:', 'Phone:']):
                break
            elif in_experience:
                experience_section.append(line)
        
        return '\n'.join(experience_section).strip()

    def _extract_skills(self, user_info):
        """Extract skills section from user info"""
        lines = user_info.split('\n')
        skills_section = []
        in_skills = False
        
        for line in lines:
            if 'Skills:' in line or 'Technical Skills:' in line or 'Core Competencies:' in line:
                in_skills = True
                continue
            elif in_skills and any(section in line for section in ['Work Experience:', 'Education:', 'Name:', 'Email:', 'Phone:']):
                break
            elif in_skills:
                skills_section.append(line)
        
        return '\n'.join(skills_section).strip()

    def _extract_company_name(self, job_description):
        """Try to extract company name from job description"""
        # Simple extraction - look for common patterns
        lines = job_description.split('\n')[:10]  # Check first 10 lines
        
        for line in lines:
            # Look for patterns like "Company: XYZ" or "XYZ is looking for"
            if 'company:' in line.lower():
                return line.split(':')[1].strip()
            elif 'is looking for' in line.lower():
                return line.split('is looking for')[0].strip()
        
        return None